---
title: "AI実装検定A級のメモ"
date: 2021-04-26T16:28:05+09:00
lastmod: 2021-04-26T16:28:05+09:00
draft: false
thumbnail: "images/noimage.jpg"
categories: [ "others" ]
tags: [ "メモ","追記予定" ]
---


## AI概論

### 特徴量とは

特徴量とは、物体が物体であると認識できるもののことを言う。

例えば、犬の画像をAIが犬と認識するには、「耳が尖っている」「四足歩行である」「体毛に覆われている」などを特徴量と言い、それを認識している必要がある。

### 教師なし学習と教師あり学習

- 教師あり学習: 入力データと正解ラベルのセットを使って学習する(※犬・猫の画像をそれぞれ、犬、猫とつけたラベルのことを正解ラベルという)
- 教師なし学習: 正解ラベルがないデータの集まりで学習をする(似た画像同士でグループ分け(クラスタリング)をする必要がある)


#### 代表的な教師あり学習

- 決定木 (ラベルをもとに分類)
- サポートベクターマシン(マージン最大化による分類)
- 線形回帰(回帰モデル)

#### 代表的な教師なし学習

- k-means(クラスタリング、似たデータを自動でグループ化)


<!--前処理関係-->

### 標本化と量子化

標本化: 一定間隔でサンプルリングし、ピクセル単位に分解すること
量子化: 各ピクセルの色の強さを、有限の数値に変換する処理

まず、標本化で、一定間隔で区切って分解をする。

続いて、量子化で、色の強さを0~255に丸める。

この標本化と量子化が画像認識において必須の前処理という作業。

標本化 → 量子化 → 入力データ作成 という工程を経て、モデルにデータを与え判定をすることができる。

<!--前処理関係-->


<!--学習〜損失値の把握、損失値の調整-->



### 回帰問題と分類問題

- 回帰問題: 数値を予測する問題(不動産の情報から価格を予測する、気温を予測するなど)
- 分類問題: カテゴリを予測する問題(犬猫の分類、メールがスパムかそうでないかなど)


### 損失関数の種類

損失関数はAIの予測と正解との誤差(損失)を表現した値のことである。

この損失関数を使うことで、AIの予測がどれぐらい間違っているかが把握できる。

#### 平均二乗誤差(MSE)

- 回帰問題向け
- 小さな誤差に対して有効
- ケアレスミスに対して強いが、大まかな理解には弱いイメージ

#### 平均絶対誤差(MAE)

- 回帰問題向け
- 大きな誤差に対して有効
- 大まかな理解に対して強いが、ケアレスミスには弱いイメージ

#### ハブ損失

- 回帰問題向け
- MSE,MAEをもとにして作られている
- 小さな誤差にはMSEを使い、大きな誤差にはMAEを使うことで、安定した学習ができる。


#### クロスエントロピー誤差

- 分類問題向け
- 二値分類、多クラス分類にも使える
- 確率分布をもとにした誤差、予測確率と実際のラベルとの差を測る


#### ハンジング誤差

- 分類問題向け
- サポートベクターマシン(SVM)で使う
- 分類境界からの距離を評価、線形分類に強い


#### Kullback-Leibler Divergence (KLダイバージェンス)

- 分類問題向け
- 確率分布比較で使う
- 2つの確率分布間の差を測定、生成モデルやベイズ推定に使用


#### スムースクロスエントロピー誤差 (Smooth Cross-Entropy)

- 分類問題向け
- 二値分類、多クラス分類にも使える
- クラス不均衡にも対応できる。

多クラス分類で、一部クラスのデータが少ないとき、クロスエントロピーで対処しきれない。

そこでクロスエントロピーをもとに改良し、クラス不均衡にも対応した。

#### ソフトマックスクロスエントロピー誤差 (Softmax Cross-Entropy Loss)

- 分類問題向け
- 多クラス分類に有効
- ソフトマックスによる確率分布を基にして誤差を計算できる

ソフトマックスとは、各クラスの出力値を確率に変換。その確率が合わせて1になるようにしたもの。

### 誤差逆伝播法(バックプロパゲーション)

ニューラルネットワークにおいて、出力と正解の誤差を、ネットワークを逆にたどって重みを修正する方法。

このとき、どのように重みを変化させるかを微分(勾配)を用いて計算する。

### バイアス項

バイアスとは、出力をずらすための定数項

例えば、y= Wx+b という重みつき入力Wxに対して、bというバイアスを与えて出力値をずらす。


### 指標

- Accuracy(正解率) : 全ての予測中、正しく予測できた割合
- Precision(適合率) : 実際の正解のうち、正しく予測できた割合


適合率は、特定のクラスにフォーカスをあて、実際に正しく予測できた割合のことをいう。

例えば、ガンのレントゲン写真からガンとガンではないの2値分類をするとき。

- ガンであると予測した総数120枚(うち、実際にガンだったレントゲンは100枚)
- ガンではないと予測した総数50枚(うち、実際にガンではなかったレントゲンは40枚)

この場合、

- ガンである場合の適合率は 100枚 / 120枚
- ガンではない場合の適合率は 40枚 / 50枚
- 正解率は 140枚 / 170枚 

である。

適合率は、特定のクラスにフォーカスを当てた場合に、正しく予測できた割合のこと。

正解率は、全体からみて、正しく予測できた割合のこと。


## 数学


### 試験に出る代表的な公式


#### 微分の基本公式

<div class="img-center"><img src="/images/Screenshot from 2025-04-26 16-56-38.png" alt=""></div>

#### 合成関数の微分


<div class="img-center"><img src="/images/Screenshot from 2025-04-26 16-56-43.png" alt=""></div>

#### 極限の基本公式

<div class="img-center"><img src="/images/Screenshot from 2025-04-26 16-56-47.png" alt=""></div>


#### 指数・対数の公式

<div class="img-center"><img src="/images/Screenshot from 2025-04-26 16-57-04.png" alt=""></div>

#### 勾配降下法

<div class="img-center"><img src="/images/Screenshot from 2025-04-26 16-59-04.png" alt=""></div>

勾配降下法とは損失を小さくなる方向に少しずつパラメータを調整していく方法。

損失関数とはAIの予測と正解とのズレ(誤差)を数値で表現したもの。この損失関数を最小にすることがAI開発の目標である(高い正解率)

- 損失: 誤判定
- 損失関数: 損失(誤判定)を数値化したもの
- 勾配降下法: 損失(誤判定)を最小にするために使うもの


#### ベクトル・ノルムの基本

<div class="img-center"><img src="/images/Screenshot from 2025-04-26 16-59-07.png" alt=""></div>

##### ベクトル

向きと大きさを持つ物。例えば(3, 4)というベクトルは、原点から横に3，縦に4進むという意味がある。この2つの要素があるベクトルを2次元ベクトルという。

1x4で4つの要素を持つベクトルを、4次元ベクトルという。

このベクトルは行列の一種である。(横、縦に長い行列。)

##### ノルム

ノルムはベクトルの長さを表現したもの。

L2ノルム(ユークリッド距離)はピタゴラスの定理(a^2 + b^2 = c^2)で求めることができる。

例えば (3, 4)であれば、

このように求めることができる。

<div class="img-center"><img src="/images/Screenshot from 2025-04-26 17-08-14.png" alt=""></div>


L1ノルム(タクシー距離)は、縦横にしか移動できない場合の移動距離の合計

(3,4)であれば、縦方向に4、横方向に3なので、足して7となる。

単にノルムとだけ書かれていた場合、一般的にはL2ノルムを意味している。


### 二次関数の最小値

<div class="img-center"><img src="/images/Screenshot from 2025-04-27 11-05-43.png" alt=""></div>

例えば、この最小値を求めるとき、平方完成を使うことで求めることができる。

<div class="img-center"><img src="/images/Screenshot from 2025-04-27 11-06-47.png" alt=""></div>

よって、答えは-1である。

### 行列


行列の形は (2 x 3)などと表現される。この場合。行が2行、列が3列となる。

行列の掛け算では、例えば`A*B`のとき、`Aの列数`とBの行数が一致しなければ計算できない。

そのため、Bは(3 x X) などと3行である必要がある。


<div class="img-center"><img src="" alt=""></div>
<div class="img-center"><img src="" alt=""></div>
<div class="img-center"><img src="" alt=""></div>



